---
title: "supercomputer_failures"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{supercomputer_failures}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(foocafeReliability)
library(rstan)
```


## Build model
```{R}

modelString <- "
  data {
    int <lower=0> Nobs;
    int <lower=0> count[Nobs];
  }

  parameters {
    real <lower=0> lambda;
  }

  model {
    count ~ poisson(lambda);

    lambda ~ gamma(5, 1);
  }
  
  generated quantities {
    //sample predicted values from the model for posterior predictive checks
    real y_rep[Nobs];
    
    for(n in 1:Nobs)
      y_rep[n] = poisson_rng(lambda);
  }
"

supercomputer_failures_model <- rstan::stan_model(model_code = modelString)


```

## Fit model to data
```{R}

supercomp_fail_list <- list(Nobs = NROW(supercomputer_failures$failure_count),
                          count = supercomputer_failures$failure_count
                          )

output <- rstan::sampling(supercomputer_failures_model, data = supercomp_fail_list, chains = 4, iter = 4000, control = list(adapt_delta = 0.9))

```

## Evaluate goodness of fit
```{R}

n <- NROW(supercomputer_failures)
K <- round(n^0.4)
a <- seq(0,1,1/K)
p <- diff(a)
m <- numeric(K)
m2 <- numeric(K)
output_vals <- rstan::extract(output)

chi_val <- qchisq(0.95,K-1)
r_b <- numeric(NROW(output_vals$lambda))
r_b2 <- numeric(NROW(output_vals$lambda))

for (jj in 1:NROW(r_b)) {
  
  thisLambda <- output_vals$lambda[jj]
  
  probs <- data.frame(
    probabilities_minus_1 = ppois(supercomputer_failures$failure_count - 1,
                                  thisLambda),
    probabilities = ppois(supercomputer_failures$failure_count,
                          thisLambda)
    )
  
  probs <- probs %>% dplyr::mutate(g = apply(probs, 1, function(x) {runif(1, min = x[1], max = x[2])} ))
  
  
  for (ii in 1:length(m)){
    m[ii] <- sum(probs$g > a[ii] & probs$g < a[ii+1])
    m2[ii] <- sum(probs$probabilities > a[ii] & probs$probabilities < a[ii+1])
  }
  
  r_b[jj] <- sum(((m - n*p)^2)/(n*p))
  r_b2[jj] <- sum(((m2 - n*p)^2)/(n*p))

}

sum(r_b > chi_val)/NROW(r_b) * 100
sum(r_b2 > chi_val)/NROW(r_b2) * 100

```



```{R}
y <- supercomputer_failures$failure_count
shinystan::launch_shinystan(output)

```
## Evaluate goodness of fit using posterior predictive checks

p = Pr(T(simulations) > T(obs))

```{R}

y <- supercomputer_failures$failure_count
y_rep <- rstan::extract(output, "y_rep")

# Taking the mean to be the test statistic:
ppp_mean <- sum(apply(output_vals$y_rep, 1, mean) > mean(y))/NROW(simulations_mean)

# Taking max to be the test statistic:
ppp_maximum <- sum(apply(output_vals$y_rep, 1, max) > max(y))/NROW(simulations_mean)

```


# Using bayesplot package with rstan output:
https://mc-stan.org/bayesplot/index.html
```{R}

x <- list(y = supercomputer_failures$failure_count,
          yrep = rstan::extract(output, "y_rep")$y_rep)
class(x) <- "foo"
pp_check.foo <- function(object, ..., type = c("multiple", "overlaid")) {
    y <- object[["y"]]
    yrep <- object[["yrep"]]
    switch(match.arg(type),
           multiple = ppc_hist(y, yrep[1:min(8, nrow(yrep)),, drop = FALSE]),
           overlaid = ppc_dens_overlay(y, yrep[1:100,, drop = FALSE]))
}
pp_check(x, type = "overlaid")

```
