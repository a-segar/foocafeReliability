---
title: "prowler_bearing_failures"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{prowler_bearing_failures}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(foocafeReliability)
library(rstan)
```


## Build model  Censored Data Example Ex 4.6 from Bayesian Reliabilty
```{R}

modelString <- "
  data {
    int <lower=0> Nobs;
    int <lower=0> Ncen;
    real <lower=0> yobs[Nobs];
    real <lower=0> ycen[Ncen];
  }

  parameters {
    real mu;
    real <lower=0> sigma_2;
  }

  model {
    real sigma;
    sigma = sqrt(sigma_2);
    
    target += lognormal_lpdf(yobs | mu, sigma);
    target += lognormal_lccdf(ycen | mu, sigma);

    mu ~ normal(6.5, 25);
    sigma_2 ~ inv_gamma(6.5, 23.5);
  }
  
  generated quantities {
  
    
    //sample predicted values from the model for posterior predictive checks
    real y_rep[Nobs+Ncen];
    
    real sigma;
    sigma = sqrt(sigma_2);
    
    for(n in 1:(Nobs+Ncen))
      y_rep[n] = lognormal_rng(mu, sigma);
  }
"

prowler_bearing_failures_model <- rstan::stan_model(model_code = modelString)


```

## Fit model to data
```{R}
failures <- prowler_bearing_failures$operating_hours[prowler_bearing_failures$right_censored == FALSE]
suspensions <- prowler_bearing_failures$operating_hours[prowler_bearing_failures$right_censored == TRUE]

prowler_bearing_fail_list <- list(Nobs = NROW(failures),
                            Ncen = NROW(suspensions),
                            yobs = failures,
                            ycen = suspensions
                          )

output <- rstan::sampling(prowler_bearing_failures_model, data = prowler_bearing_fail_list, chains = 4, iter = 4000, control = list(adapt_delta = 0.9))

```

```{R}

costTableList <- list()
t = seq(1,3500,100)

output_vals <- rstan::extract(output)

for (ii in 1:NROW(output_vals)){

  thisMu <- output_vals$mu[ii]
  thisSigma <- sqrt(output_vals$sigma_2[ii])
  
  get_reliability <- function(thisMu, thisSigma){
    f1 <- function(t){
      1 - pnorm((log(t) - thisMu)/thisSigma)
    }
    return(f1)
  }

  reliability <- get_reliability(thisMu, thisSigma)

  costTable <- data.frame("t" = t,
                          "reliability" = numeric(NROW(t)))

  costTable$reliability <- reliability(t)
  
  costTableList[[ii]] <- costTable
}

temp <- lapply(costTableList, '[', 2) %>% dplyr::bind_cols()

data <- data.frame(t = t,
                   meanVal = apply(temp, 1, mean),
                   LQ = apply(temp, 1, function(x) {quantile(x, 0.05)}),
                   UQ = apply(temp, 1, function(x) {quantile(x, 0.95)}))


ggplot(data = data, aes(t)) +
  geom_line(aes(y = meanVal)) +
  geom_ribbon(aes(ymin = LQ, ymax = UQ), alpha = 0.05)
  

```


## Evaluate goodness of fit
```{R}
params <- data.frame("meanlog" = rstan::extract(output)["mu"],
                     "sdlog" = rstan::extract(output)["sigma"])
colnames(params) <- c("meanlog","sdlog")

bayesian_chi_squared_test(y = prowler_bearing_failures$operating_hours,
                          distribution_fun = plnorm,
                          params = params,
                          data_type = "censored",
                          censored = prowler_bearing_failures$right_censored)

```



```{R}

output_vals <- extract(output, c("mu", "sigma"))

y = prowler_bearing_failures$operating_hours

censored_data <- y[prowler_bearing_failures$right_censored == TRUE]

generated_y <- numeric(NROW(censored_data))

for (ii in 1:NROW(censored_data)){
  this_U = runif(1, plnorm(censored_data[ii],output_vals$mu[jj], output_vals$sigma[jj]), 1)
  generated_y[ii] <- as.numeric(quantile(rlnorm(100000, output_vals$mu[jj], output_vals$sigma[jj]), this_U))
}

y_new <- y
y_new[prowler_bearing_failures$right_censored == TRUE] <- generated_y
  
```


```{R}

library(bayesplot)

x <- list(y = y_new,
          yrep = rstan::extract(output, "y_rep")$y_rep)
class(x) <- "foo"
pp_check.foo <- function(object, ..., type = c("multiple", "overlaid")) {
    y <- object[["y"]]
    yrep <- object[["yrep"]]
    switch(match.arg(type),
           multiple = ppc_hist(y, yrep[1:min(8, nrow(yrep)),, drop = FALSE]),
           overlaid = ppc_dens_overlay(y, yrep[1:100,, drop = FALSE]))
}
pp_check(x, type = "overlaid")

```


Perhaps the best way to go is to calculate the pp check for the suspensions using the cdf and the failures using the pdf. So y_rep should be taken from the cdf to be compared with suspensions, and from the pdf to be compared with the failures.
